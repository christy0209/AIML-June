The objective of the support vector machine algorithm is to find a hyperplane in an N-dimensional space(N â€” the number of features) 
that distinctly classifies the data points.

Can be used for both Classification and Regression.

for a 1d space hyper plane will be a dot(point)
for a 2d space hyper plane will be a  line
for a 3d space  hypre plane will be a plane
in general for a N-dimensional space, hyper plane will be of dimenssion (N-1)



To separate the two classes of data points, there are many possible hyperplanes that could be chosen. 
Our objective is to find a plane that has the maximum margin, i.e the maximum distance between data points of both classes. 
Maximizing the margin distance provides some reinforcement so that future data points can be classified with more confidence.


The best hyperplane cuts the space in such a way that it maximizes the margin from the support vectors.
Support vectors are data points that are closer to the hyperplane and influence the position and orientation of the hyperplane.

SVM Kernals
SVM algorithms use a set of mathematical functions that are defined as the kernel. 
The function of kernel is to take data as input and transform it into the required form. 
Different SVM algorithms use different types of kernel functions. These functions can be different types. 
For example linear, nonlinear, polynomial, radial basis function (RBF), and sigmoid.


Kernal Trick in SVM
Any non linear data can be upgraded to a higher dimension to make it linear.

useful links
https://data-flair.training/blogs/svm-support-vector-machine-tutorial/
https://data-flair.training/blogs/svm-kernel-functions/
